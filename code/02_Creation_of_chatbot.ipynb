{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97561240",
   "metadata": {},
   "source": [
    "## Part 3: Creating a customised chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9cbe72",
   "metadata": {},
   "source": [
    "Based on part 1 and 2 in the earlier notebooks, I have extracted the necessary data that I need as context for building a customised chatbot. \n",
    "The following portion of this codebook will include:\n",
    "- Part 3a: Creating a default chatbot without introducing any system prompt\n",
    "- Part 3b: Creating an improved chatbot with the use of system prompt\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "365d3559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from llama_index import Document, GPTVectorStoreIndex, ServiceContext\n",
    "from llama_index.readers import SimpleDirectoryReader\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50345cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will need to use our own OpenAI API key. This key is removed due to privacy issue.\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d00197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"../extra_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b38c4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 125 docs\n"
     ]
    }
   ],
   "source": [
    "filename_fn = lambda filename: {'file_name': filename}\n",
    "my_docs = SimpleDirectoryReader(input_dir=\"../data\", exclude_hidden=True, file_metadata=filename_fn).load_data()\n",
    "\n",
    "print(f\"Loaded {len(my_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b80b4",
   "metadata": {},
   "source": [
    "### Part 3a: Creating a default chatbot without any system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e438825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the original without any prompts for the chatbot\n",
    "original_service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd3edae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_index = GPTVectorStoreIndex.from_documents(documents=my_docs, service_context=original_service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29fd12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query_engine = original_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61359510",
   "metadata": {},
   "source": [
    "#### Testing out some questions with the original query engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7c78d5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A candidate must earn a fixed monthly salary starting from $5,000 to be eligible for an employment pass. However, candidates in the financial services sector need to earn higher salaries to qualify.\n",
      "\n",
      "This query took: 8.021786212921143 secs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "response = original_query_engine.query(\"How much salary must a candidate earn to be eligible for employment pass?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bbc9a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can earn 20 points under the salary criteria by having a fixed monthly salary that is at or above the 90th percentile compared to the salary benchmarks by sector.\n",
      "\n",
      "This query took: 8.367677211761475 secs.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = original_query_engine.query(\"How do I earn 20 points under the salary criteria?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "80ecb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can find information about your company's diversity in the \"Diversity\" tab of the Workforce Insights tool, which can be accessed via the myMOM Portal.\n",
      "\n",
      "This query took: 8.531136989593506 secs.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = original_query_engine.query(\"Where can I find information about my company's diversity?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6843a91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the candidate from Fudan University will earn 20 points under the qualification criterion.\n"
     ]
    }
   ],
   "source": [
    "response = original_query_engine.query(\"I have a candidate from Fudan University, will she earn 20 points under the qualification criterion?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0bfa382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your candidate aged 40 should be earning $12,213 from the Construction sector in order to be awarded with 20 points.\n"
     ]
    }
   ],
   "source": [
    "response = original_query_engine.query(\"How much should my candidate aged 40 be earning from Construction sector to be awarded with 20 points?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "294c337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your candidate from the Accommodation sector should be earning $9,369 to be awarded 20 points.\n"
     ]
    }
   ],
   "source": [
    "response = original_query_engine.query(\"How much should my candidate from Accommodation be earning to be awarded 20 points?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2a772",
   "metadata": {},
   "source": [
    "**Based on the above queries that we have tested, the chatbot is able to come up with succint answers from the queries we have asked about qualifications, salary. But, we would ideally hope that the chatbot is able to include more context to how it derived the answer.** \n",
    "\n",
    "**As for the runtime, each query took about 8 to 9 secs to complete.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e0a03",
   "metadata": {},
   "source": [
    "#### Generating the questions to measure the performance of the original query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ae8aed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the documents\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(my_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b277c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen_query = (\n",
    "    \"You are working at Ministry of Manpower focusing on eligibiity requirements of the employment pass. \\\n",
    "    There is a new complementarity assessment framework that will assess the eligibility of all prospective employment pass holders. \\\n",
    "    Your task is to setup all possible questions and requests, \\\n",
    "    using the provided context from documents on eligibility of employment pass, \\\n",
    "    formulate questions that capture important facts from the context. \\\n",
    "    Restrict the question to the context information provided.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8c92eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    my_docs,\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=original_service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f7934eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  30  questions\n"
     ]
    }
   ],
   "source": [
    "questions = dataset_generator.generate_questions_from_nodes(num=30)\n",
    "print(\"Generated \", len(questions), \" questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bafffab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../qns_and_eval/original_evaluation_questions.txt\", \"w\") as f:\n",
    "    for question in questions:\n",
    "        f.write(question + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "529febe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_contexts = []\n",
    "original_answers = []\n",
    "\n",
    "for question in questions:\n",
    "    response = original_query_engine.query(question)\n",
    "    original_contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    original_answers.append(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4f5f4c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████                       | 1/2 [01:58<01:58, 118.37s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 08 Nov 2023 09:41:14 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '822cda7e7dee46f7-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "100%|██████████████████████████████████████████████| 2/2 [04:42<00:00, 141.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/2 [00:00<?, ?it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "100%|█████████████████████████████████████████████| 2/2 [34:36<00:00, 1038.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.8767, 'answer_relevancy': 0.9227, 'faithfulness': 0.8350}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "original_ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": original_answers,\n",
    "        \"contexts\": original_contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "original_result = evaluate(original_ds, [answer_relevancy, faithfulness])\n",
    "print(original_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b66600d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  50  questions\n"
     ]
    }
   ],
   "source": [
    "questions = dataset_generator.generate_questions_from_nodes(num=50)\n",
    "print(\"Generated \", len(questions), \" questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6953afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../qns_and_eval/train_questions.txt\", \"w\") as f:\n",
    "    for question in questions:\n",
    "        f.write(question + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0ede4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_generator = DatasetGenerator.from_documents(\n",
    "    my_docs[90:],  # In our training set we loaded 34 docs, so we will now use the remaining starting from 35\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=original_service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "257491a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  50  questions\n"
     ]
    }
   ],
   "source": [
    "eval_questions = eval_dataset_generator.generate_questions_from_nodes(num=50)\n",
    "print(\"Generated \", len(eval_questions), \" questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c42bbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../qns_and_eval/eval_questions.txt\", \"w\") as f:\n",
    "    for question in eval_questions:\n",
    "        f.write(question + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c5a44",
   "metadata": {},
   "source": [
    "#### Generating scores for training and evaluation based on original query engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35c1a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts = []\n",
    "train_answers = []\n",
    "\n",
    "for question in questions:\n",
    "    response = original_query_engine.query(question)\n",
    "    train_contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    train_answers.append(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f37034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████▌                       | 2/4 [01:41<01:39, 49.66s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "100%|██████████████████████████████████████████████| 4/4 [13:26<00:00, 201.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████▌                                  | 1/4 [07:52<23:36, 472.16s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 05 Nov 2023 18:57:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821744021bcf3e12-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "100%|██████████████████████████████████████████████| 4/4 [32:16<00:00, 484.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.8160, 'answer_relevancy': 0.9140, 'faithfulness': 0.7370}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "original_ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": train_answers,\n",
    "        \"contexts\": train_contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "train_result = evaluate(original_ds, [answer_relevancy, faithfulness])\n",
    "print(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18ad5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_contexts = []\n",
    "eval_answers = []\n",
    "\n",
    "for eval_question in eval_questions:\n",
    "    eval_response = original_query_engine.query(eval_question)\n",
    "    eval_contexts.append([x.node.get_content() for x in eval_response.source_nodes])\n",
    "    eval_answers.append(str(eval_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9bab20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 4/4 [04:13<00:00, 63.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████▌           | 3/4 [12:50<04:17, 257.04s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sun, 05 Nov 2023 20:01:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '8217a19fad663e4d-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "100%|██████████████████████████████████████████████| 4/4 [24:01<00:00, 360.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.8285, 'answer_relevancy': 0.9613, 'faithfulness': 0.7280}\n"
     ]
    }
   ],
   "source": [
    "original_eval_ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": eval_questions,\n",
    "        \"answer\": eval_answers,\n",
    "        \"contexts\": eval_contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "eval_result = evaluate(original_eval_ds, [answer_relevancy, faithfulness])\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb4e02",
   "metadata": {},
   "source": [
    "### Part 3b: Improved chatbot with system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a75f42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the improved service context with context_window and system prompt added for the chatbot\n",
    "improved_service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0), \n",
    "    context_window=2048, \n",
    "    system_prompt = \"You are an expert who understands the eligibility criteria of employment pass and your job is to answer questions related to the COMPASS and all relevant requirements. Keep your answers factual and provide more context. When asked about salary criteria or C1, include both the age and sector assumed if not provided before answering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62353029",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_index = GPTVectorStoreIndex.from_documents(documents=my_docs, service_context=improved_service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee155726",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_query_engine = improved_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a28fe81",
   "metadata": {},
   "source": [
    "#### Testing out some questions with the improved query engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "be6b1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A candidate must have a fixed monthly salary starting from $5,000 to be eligible for an Employment Pass. The salary increases progressively with age, up to $10,500 for those in the mid-40s. However, candidates in the financial services sector must earn at least $5,500, with the salary also increasing progressively with age up to $11,500 for those in the mid-40s.\n",
      "\n",
      "This query took: 18.43025517463684 secs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "response = improved_query_engine.query(\"How much salary must a candidate earn to be eligible for employment pass?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c960c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To earn 20 points under the salary criteria, your candidate's fixed monthly salary should be at or above the 90th percentile of the salary benchmarks by sector.\n",
      "\n",
      "This query took: 8.806796073913574 secs.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = improved_query_engine.query(\"How do I earn 20 points under the salary criteria?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "20c3a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can find information about your company's diversity in the \"Diversity\" tab of the Workforce Insights tool on the myMOM Portal. This tab shows you the top nationalities of PMETs (Professionals, Managers, Executives, and Technicians) in your firm, allowing you to assess the diversity of your workforce.\n",
      "\n",
      "This query took: 6.932214736938477 secs.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = improved_query_engine.query(\"Where can I find information about my company's diversity?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7efbe2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be awarded 10 points in the Construction sector, your candidate should be earning a salary of $4,770 or above.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = improved_query_engine.query(\"How much should my candidate be earning from Construction sector to be awarded 10 points?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e881e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your candidate, aged 40, should be earning a minimum salary of $12,213 from the Construction sector in order to be awarded with 20 points.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = improved_query_engine.query(\"How much should my candidate aged 40 be earning from Construction sector to be awarded with 20 points?\")\n",
    "print(response)\n",
    "end = time.time()\n",
    "print(\"\")\n",
    "print(f\"This query took: {end-start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d2da61ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the required salary for a candidate to be awarded 10 points varies depending on the age and sector. Could you please provide the age and sector of your candidate so that I can give you the specific salary requirement?\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = improved_query_engine.query(\"How much should my candidate be earning to be awarded 10 points?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf076a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information for the Accommodation sector, the required salary for 20 points (90th percentile of local PMETs) varies depending on the age of the candidate. \n",
      "\n",
      "For candidates aged 37, the required salary for 20 points is $9,104. \n",
      "For candidates aged 38, the required salary for 20 points is $9,369. \n",
      "For candidates aged 39, the required salary for 20 points is $9,635. \n",
      "For candidates aged 40, the required salary for 20 points is $9,900. \n",
      "For candidates aged 41, the required salary for 20 points is $10,165. \n",
      "For candidates aged 42, the required salary for 20 points is $10,431. \n",
      "For candidates aged 43, the required salary for 20 points is $10,696. \n",
      "For candidates aged 44, the required salary for 20 points is $10,962. \n",
      "For candidates aged 45 and above, the required salary for 20 points is $11,227. \n",
      "\n",
      "Please note that these figures are specific to the Accommodation sector and are based on the 90th percentile of local PMETs.\n"
     ]
    }
   ],
   "source": [
    "response = improved_query_engine.query(\"How much should my candidate from Accommodation be earning to be awarded 20 points?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8941f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information for the Manufacturing sector, the required salary for a candidate to be awarded 20 points is as follows:\n",
      "\n",
      "- For candidates aged 40: $13,811\n",
      "- For candidates aged 41: $14,211\n",
      "- For candidates aged 42: $14,611\n",
      "- For candidates aged 43: $15,011\n",
      "- For candidates aged 44: $15,411\n",
      "- For candidates aged 45 and above: $15,811\n",
      "\n",
      "Please note that these salary figures represent the 90th percentile of local PMETs (Professionals, Managers, Executives, and Technicians) in the Manufacturing sector.\n"
     ]
    }
   ],
   "source": [
    "response = improved_query_engine.query(\"How much should my candidate from Manufacturing be earning to be awarded 20 points?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563ff90",
   "metadata": {},
   "source": [
    "#### Generating the training and evaluation questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8e659e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the documents\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(my_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "17c7e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen_query = (\n",
    "    \"You are working at Ministry of Manpower focusing on eligibiity requirements of the employment pass. \\\n",
    "    There is a new complementarity assessment framework that will assess the eligibility of all prospective employment pass holders. \\\n",
    "    Your task is to setup all possible questions and requests, \\\n",
    "    using the provided context from documents on eligibility of employment pass, \\\n",
    "    formulate questions that capture important facts from the context. \\\n",
    "    Restrict the question to the context information provided.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "42c8de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_dataset_generator = DatasetGenerator.from_documents(\n",
    "    my_docs,\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=improved_service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "06446b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  30  questions\n"
     ]
    }
   ],
   "source": [
    "improved_questions = improved_dataset_generator.generate_questions_from_nodes(num=30)\n",
    "print(\"Generated \", len(questions), \" questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b953b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../qns_and_eval/improved_evaluation_questions.txt\", \"w\") as f:\n",
    "    for question in improved_questions:\n",
    "        f.write(question + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4885d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_eval_contexts = []\n",
    "improved_eval_answers = []\n",
    "\n",
    "for question in improved_questions:\n",
    "    improved_eval_response = improved_query_engine.query(question)\n",
    "    improved_eval_contexts.append([x.node.get_content() for x in improved_eval_response.source_nodes])\n",
    "    improved_eval_answers.append(str(improved_eval_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "838b5df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 2/2 [03:05<00:00, 92.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/2 [00:00<?, ?it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 50%|██████████████████████▌                      | 1/2 [27:56<27:56, 1676.33s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "100%|█████████████████████████████████████████████| 2/2 [48:17<00:00, 1448.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.8310, 'answer_relevancy': 0.9606, 'faithfulness': 0.7322}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "improved_eval_ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": improved_questions,\n",
    "        \"answer\": improved_eval_answers,\n",
    "        \"contexts\": improved_eval_contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "improved_eval_result = evaluate(improved_eval_ds, [answer_relevancy, faithfulness])\n",
    "print(improved_eval_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87237f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  50  questions\n"
     ]
    }
   ],
   "source": [
    "improved_questions = improved_dataset_generator.generate_questions_from_nodes(num=50)\n",
    "print(\"Generated \", len(questions), \" questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "224ac9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../qns_and_eval/improved_train_questions.txt\", \"w\") as f:\n",
    "    for question in improved_questions:\n",
    "        f.write(question + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e78322f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_eval_dataset_generator = DatasetGenerator.from_documents(\n",
    "    my_docs[90:],  # In our training set we loaded 90 docs, so we will now use the remaining for eval.\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=improved_service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cace9aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  50  questions\n"
     ]
    }
   ],
   "source": [
    "improved_eval_questions = improved_eval_dataset_generator.generate_questions_from_nodes(num=50)\n",
    "print(\"Generated \", len(improved_eval_questions), \" questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "57a954bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../qns_and_eval/improved_eval_questions.txt\", \"w\") as f:\n",
    "    for question in improved_eval_questions:\n",
    "        f.write(question + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc06c951",
   "metadata": {},
   "source": [
    "#### Generating scores for training and evaluation based on improved query engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c81b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_train_contexts = []\n",
    "improved_train_answers = []\n",
    "\n",
    "for question in improved_questions:\n",
    "    improved_response = improved_query_engine.query(question)\n",
    "    improved_train_contexts.append([x.node.get_content() for x in improved_response.source_nodes])\n",
    "    improved_train_answers.append(str(improved_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae469c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/4 [00:00<?, ?it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 11:31:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821cf4635a594011-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      " 25%|███████████▌                                  | 1/4 [11:00<33:00, 660.25s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
      " 50%|███████████████████████                       | 2/4 [25:18<25:53, 776.63s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 11:56:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821d191909c54dc8-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 12:56:02 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821d6fdf88e74048-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 13:06:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821d7efe5e473f6e-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "100%|███████████████████████████████████████████| 4/4 [1:55:55<00:00, 1738.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/4 [00:00<?, ?it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 13:27:26 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821d9de02bb84097-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 13:54:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821dc5cd5d3a4637-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "100%|███████████████████████████████████████████| 4/4 [1:08:41<00:00, 1030.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.8557, 'answer_relevancy': 0.9429, 'faithfulness': 0.7833}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "improved_ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": improved_questions,\n",
    "        \"answer\": improved_train_answers,\n",
    "        \"contexts\": improved_train_contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "improved_train_result = evaluate(improved_ds, [answer_relevancy, faithfulness])\n",
    "print(improved_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c03edc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_eval_contexts = []\n",
    "improved_eval_answers = []\n",
    "\n",
    "for improved_eval_question in improved_eval_questions:\n",
    "    improved_eval_response = improved_query_engine.query(improved_eval_question)\n",
    "    improved_eval_contexts.append([x.node.get_content() for x in improved_eval_response.source_nodes])\n",
    "    improved_eval_answers.append(str(improved_eval_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c619f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 4/4 [05:00<00:00, 75.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████▌                                  | 1/4 [05:12<15:37, 312.40s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 07 Nov 2023 13:17:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '8225d8089eb64104-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      " 50%|███████████████████████                       | 2/4 [17:06<18:17, 548.57s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 07 Nov 2023 13:44:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '8225f48a3e3e5fae-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "100%|██████████████████████████████████████████████| 4/4 [44:09<00:00, 662.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.7730, 'answer_relevancy': 0.9860, 'faithfulness': 0.6357}\n"
     ]
    }
   ],
   "source": [
    "improved_eval_ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": improved_eval_questions,\n",
    "        \"answer\": improved_eval_answers,\n",
    "        \"contexts\": improved_eval_contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "improved_eval_result = evaluate(improved_eval_ds, [answer_relevancy, faithfulness])\n",
    "print(improved_eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1318c5f",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939ef75",
   "metadata": {},
   "source": [
    "Based on the execution time, the RAG score metrics as well as the quality of content provided can be summarised in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aeab66",
   "metadata": {},
   "source": [
    "| Query engine         | RAGAS Score | Answer Relevancy | Faithfulness | \n",
    "|----------------------|-------------|------------------|--------------|\n",
    "| Original (GPT-3.5-Turbo) | 0.8160 | 0.9140        | 0.7370       | \n",
    "| Improved with system prompt (GPT-3.5-Turbo) | 0.8557| 0.9429      | 0.7833 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68ee0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We store the vectors of all the documents that we have curated for our chatbot that is to be deployed on streamlit\n",
    "improved_index.storage_context.persist(persist_dir=\"../streamlit/improved_index.vecstore\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
